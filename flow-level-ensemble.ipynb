{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble unsupervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/PRO/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from config import whisper_config\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.cluster import KMeans\n",
    "from model import AutoEncoder, Dataset, train_kmeans, test_kmeans, train_ae, test_ae, get_flows, transform\n",
    "from model import get_metrics\n",
    "from plot import plot_cdf, plot_line\n",
    "\n",
    "MAX_LEN = whisper_config[\"n_fft\"] * 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "benign_filenames = [os.path.join(\"train_set\", \"benign\" + str(i) + \".csv\") \n",
    "                    for i in range(1, 3)]\n",
    "attack_filenames = [os.path.join(\"attack_set\", x) for x in \n",
    "                    os.listdir(\"attack_set\") if x.endswith(\".csv\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_ensemble(datac, dataw, labels, kmeans_load_path,\n",
    "         aec_input_dim, aec_load_path, aew_input_dim, aew_load_path, \n",
    "         kmeans_scale=7, aec_scale=10, aew_scale=3,\n",
    "         test_data_aug=False, vote_method=\"majority\", plot_dir=None):\n",
    "    \n",
    "    kmeans_preds, kmeans_ratios, kmeans_loss_list, kmeans_threshold = \\\n",
    "        test_kmeans(dataw, kmeans_load_path, whisper_config, scale=kmeans_scale)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    model_aec = AutoEncoder(aec_input_dim, decoder_sigmoid=True)\n",
    "    model_aec.load_state_dict(torch.load(os.path.join(aec_load_path, \"model.pt\")))\n",
    "    model_aec.to(device)\n",
    "    with open(os.path.join(aec_load_path, \"train_loss.json\"), \"r\") as f:\n",
    "        loss_list = json.load(f)\n",
    "    threshold = torch.tensor(loss_list).mean().item()\n",
    "    aec_preds, aec_ratios, aec_loss_list, aec_threshold = \\\n",
    "        test_ae(datac, model_aec, device, criterion, threshold, \n",
    "                scale=aec_scale, test_data_aug=False, decoder_sigmoid=True) \n",
    "    \n",
    "    model_aew = AutoEncoder(aew_input_dim)\n",
    "    model_aew.load_state_dict(torch.load(os.path.join(aew_load_path, \"model.pt\")))\n",
    "    model_aew.to(device)\n",
    "    with open(os.path.join(aew_load_path, \"train_loss.json\"), \"r\") as f:\n",
    "        loss_list = json.load(f)\n",
    "    threshold = torch.tensor(loss_list).mean().item()\n",
    "    aew_preds, aew_ratios, aew_loss_list, aew_threshold = \\\n",
    "        test_ae(dataw, model_aew, device, criterion, threshold, \n",
    "                scale=aew_scale, test_data_aug=test_data_aug, decoder_sigmoid=False)\n",
    "\n",
    "    # preds = np.sign(np.array(kmeans_preds) + np.array(aec_preds) + np.array(aew_preds))\n",
    "    preds_majority, preds_positive, preds_weighted = [], [], []\n",
    "    for idx in range(len(kmeans_preds)):\n",
    "        preds_majority.append(np.sign(kmeans_preds[idx] + aec_preds[idx] + aew_preds[idx]))\n",
    "        if kmeans_preds[idx] == -1 or aec_preds[idx] == -1 or aew_preds[idx] == -1:\n",
    "            preds_positive.append(-1)\n",
    "        else:\n",
    "            preds_positive.append(1)\n",
    "        preds_weighted.append(np.sign(kmeans_preds[idx] * kmeans_ratios[idx] +\n",
    "                                        aec_preds[idx] * aec_ratios[idx] + \n",
    "                                        aew_preds[idx] * aew_ratios[idx]))\n",
    "    return {\n",
    "        \"labels\": labels,\n",
    "        \"kmeans\": kmeans_preds,\n",
    "        \"aec\": aec_preds,\n",
    "        \"aew\": aew_preds,\n",
    "        \"preds_majority\": preds_majority,\n",
    "        \"preds_positive\": preds_positive,\n",
    "        \"preds_weighted\": preds_weighted,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ensemble_result(df_test, test_data_aug, use_short_flow, \n",
    "                        kmeans_load_path, aec_input_dim, aec_load_path, \n",
    "                        aew_input_dim, aew_load_path, vote_method=\"majority\",\n",
    "                        plot_dir=None):\n",
    "    \n",
    "    test_packet_data, test_packet_labels, test_flow_data, test_flow_labels  \\\n",
    "    = transform(get_flows(df_test), feature_type=\"encoding\" \n",
    "                ,data_type=\"test\", test_data_aug=test_data_aug)\n",
    "    data_encoding = test_flow_data if not use_short_flow else test_flow_data + test_packet_data\n",
    "    labels_encoding = test_flow_labels if not use_short_flow else test_flow_labels + test_packet_labels\n",
    "\n",
    "    test_packet_data, test_packet_labels, test_flow_data, test_flow_labels \\\n",
    "    = transform(get_flows(df_test), data_type=\"test\", test_data_aug=test_data_aug)\n",
    "    data_whisper = test_flow_data if not use_short_flow else test_flow_data + test_packet_data\n",
    "    labels_whisper = test_flow_labels if not use_short_flow else test_flow_labels + test_packet_labels\n",
    "\n",
    "    assert len(labels_encoding) == len(labels_whisper), \\\n",
    "        print(f\"len labels_encoding: {len(labels_encoding)}, len labels_whisper: {len(labels_whisper)}\")\n",
    "    for idx in range(len(labels_encoding)):\n",
    "        assert labels_encoding[idx] == labels_whisper[idx]\n",
    "    \n",
    "    data_dict = test_ensemble(data_encoding, data_whisper, labels_whisper, \n",
    "                        kmeans_load_path, aec_input_dim, aec_load_path, aew_input_dim, \n",
    "                        aew_load_path, test_data_aug=test_data_aug, vote_method=vote_method)\n",
    "    \n",
    "    # if plot_dir is not None:\n",
    "    #     plot_cdf(, kmeans_loss_list, \"kmeans\", plot_dir)\n",
    "\n",
    "    metric_dict = {}\n",
    "    for key in [\"kmeans\", \"aec\", \"aew\", \"preds_majority\", \"preds_positive\", \"preds_weighted\"]:\n",
    "        metric_dict[key] = get_metrics(data_dict[\"labels\"], data_dict[key])\n",
    "    \n",
    "    return metric_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_DATA_AUG = True\n",
    "USE_SHORT_FLOW = True\n",
    "\n",
    "accuracy_dict = {}\n",
    "suffix = \"-all\" if USE_SHORT_FLOW else \"-long\"\n",
    "train_benign_filename = \"dataset/benign_small.csv\"\n",
    "\n",
    "aec_input_dim = MAX_LEN\n",
    "aew_input_dim = whisper_config[\"n_fft\"] // 2 + 1\n",
    "kmeans_save_path = os.path.join(\"model\", \"whisper\", \"kmeans\"+suffix, \n",
    "                    os.path.basename(train_benign_filename), \"kmeans.json\")\n",
    "aec_save_dir = os.path.join(\"model\", \"autoencoding\"+suffix, \n",
    "                        os.path.basename(train_benign_filename))\n",
    "aew_save_dir = os.path.join(\"model\", \"whisper\", \"autoencoder\"+suffix, \n",
    "                        os.path.basename(train_benign_filename))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Frequency features + KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/PRO/lib/python3.10/site-packages/torch/functional.py:632: UserWarning: stft will soon require the return_complex parameter be given for real inputs, and will further require that return_complex=True in a future PyTorch release. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:801.)\n",
      "  return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(train_benign_filename)\n",
    "train_df[\"label\"] = 1\n",
    "train_packet_data, train_packet_labels, train_flow_data, train_flow_labels \\\n",
    "= transform(get_flows(train_df))\n",
    "\n",
    "train_data = train_flow_data if not USE_SHORT_FLOW else train_flow_data + train_packet_data\n",
    "train_labels = train_flow_labels if not USE_SHORT_FLOW else train_flow_labels + train_packet_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/PRO/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_kmeans(train_data, kmeans_save_path, whisper_config[\"val_K\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Frequency features + AutoEncoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 98.1166\n",
      "Epoch 2/50, Loss: 23.9330\n",
      "Epoch 3/50, Loss: 5.0799\n",
      "Epoch 4/50, Loss: 1.9488\n",
      "Epoch 5/50, Loss: 0.7033\n",
      "Epoch 6/50, Loss: 2.9570\n",
      "Epoch 7/50, Loss: 0.3255\n",
      "Epoch 8/50, Loss: 2.7003\n",
      "Epoch 9/50, Loss: 0.8728\n",
      "Epoch 10/50, Loss: 0.5623\n",
      "Epoch 11/50, Loss: 0.9623\n",
      "Epoch 12/50, Loss: 0.4802\n",
      "Epoch 13/50, Loss: 0.3182\n",
      "Epoch 14/50, Loss: 0.6932\n",
      "Epoch 15/50, Loss: 0.7875\n",
      "Epoch 16/50, Loss: 0.2908\n",
      "Epoch 17/50, Loss: 0.7281\n",
      "Epoch 18/50, Loss: 0.2246\n",
      "Epoch 19/50, Loss: 0.5675\n",
      "Epoch 20/50, Loss: 0.5423\n",
      "Epoch 21/50, Loss: 0.2764\n",
      "Epoch 22/50, Loss: 1.2582\n",
      "Epoch 23/50, Loss: 0.6044\n",
      "Epoch 24/50, Loss: 0.3076\n",
      "Epoch 25/50, Loss: 0.3734\n",
      "Epoch 26/50, Loss: 0.3808\n",
      "Epoch 27/50, Loss: 0.6041\n",
      "Epoch 28/50, Loss: 0.3547\n",
      "Epoch 29/50, Loss: 0.6665\n",
      "Epoch 30/50, Loss: 0.6599\n",
      "Epoch 31/50, Loss: 0.6247\n",
      "Epoch 32/50, Loss: 0.2840\n",
      "Epoch 33/50, Loss: 1.9269\n",
      "Epoch 34/50, Loss: 2.5784\n",
      "Epoch 35/50, Loss: 1.2231\n",
      "Epoch 36/50, Loss: 0.4141\n",
      "Epoch 37/50, Loss: 1.5400\n",
      "Epoch 38/50, Loss: 1.2441\n",
      "Epoch 39/50, Loss: 0.4358\n",
      "Epoch 40/50, Loss: 0.7861\n",
      "Epoch 41/50, Loss: 0.5995\n",
      "Epoch 42/50, Loss: 0.3244\n",
      "Epoch 43/50, Loss: 0.5051\n",
      "Epoch 44/50, Loss: 0.4406\n",
      "Epoch 45/50, Loss: 0.3123\n",
      "Epoch 46/50, Loss: 0.5339\n",
      "Epoch 47/50, Loss: 2.3186\n",
      "Epoch 48/50, Loss: 0.8083\n",
      "Epoch 49/50, Loss: 2.7487\n",
      "Epoch 50/50, Loss: 0.7312\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_aew = AutoEncoder(aew_input_dim).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model_aew.parameters(), lr=0.01, weight_decay=1e-5)\n",
    "train_ae(torch.tensor(train_data), torch.tensor(train_labels), aew_save_dir,\n",
    "         model_aew, criterion, optimizer, device, num_epochs=50)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Time features + AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(train_benign_filename)\n",
    "train_df[\"label\"] = 1\n",
    "train_packet_data_, train_packet_labels_, train_flow_data_, train_flow_labels_ \\\n",
    "= transform(get_flows(train_df), feature_type=\"encoding\")\n",
    "\n",
    "train_data_ = train_flow_data_ if not USE_SHORT_FLOW else train_flow_data_ + train_packet_data_\n",
    "train_labels_ = train_flow_labels_ if not USE_SHORT_FLOW else train_flow_labels_ + train_packet_labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 0.0816\n",
      "Epoch 2/50, Loss: 0.0461\n",
      "Epoch 3/50, Loss: 0.0254\n",
      "Epoch 4/50, Loss: 0.0206\n",
      "Epoch 5/50, Loss: 0.0150\n",
      "Epoch 6/50, Loss: 0.0207\n",
      "Epoch 7/50, Loss: 0.0185\n",
      "Epoch 8/50, Loss: 0.0141\n",
      "Epoch 9/50, Loss: 0.0125\n",
      "Epoch 10/50, Loss: 0.0024\n",
      "Epoch 11/50, Loss: 0.0128\n",
      "Epoch 12/50, Loss: 0.0070\n",
      "Epoch 13/50, Loss: 0.0020\n",
      "Epoch 14/50, Loss: 0.0052\n",
      "Epoch 15/50, Loss: 0.0029\n",
      "Epoch 16/50, Loss: 0.0031\n",
      "Epoch 17/50, Loss: 0.0041\n",
      "Epoch 18/50, Loss: 0.0047\n",
      "Epoch 19/50, Loss: 0.0039\n",
      "Epoch 20/50, Loss: 0.0037\n",
      "Epoch 21/50, Loss: 0.0063\n",
      "Epoch 22/50, Loss: 0.0057\n",
      "Epoch 23/50, Loss: 0.0041\n",
      "Epoch 24/50, Loss: 0.0017\n",
      "Epoch 25/50, Loss: 0.0058\n",
      "Epoch 26/50, Loss: 0.0083\n",
      "Epoch 27/50, Loss: 0.0056\n",
      "Epoch 28/50, Loss: 0.0073\n",
      "Epoch 29/50, Loss: 0.0030\n",
      "Epoch 30/50, Loss: 0.0017\n",
      "Epoch 31/50, Loss: 0.0021\n",
      "Epoch 32/50, Loss: 0.0029\n",
      "Epoch 33/50, Loss: 0.0051\n",
      "Epoch 34/50, Loss: 0.0014\n",
      "Epoch 35/50, Loss: 0.0028\n",
      "Epoch 36/50, Loss: 0.0044\n",
      "Epoch 37/50, Loss: 0.0027\n",
      "Epoch 38/50, Loss: 0.0003\n",
      "Epoch 39/50, Loss: 0.0013\n",
      "Epoch 40/50, Loss: 0.0018\n",
      "Epoch 41/50, Loss: 0.0039\n",
      "Epoch 42/50, Loss: 0.0004\n",
      "Epoch 43/50, Loss: 0.0038\n",
      "Epoch 44/50, Loss: 0.0059\n",
      "Epoch 45/50, Loss: 0.0023\n",
      "Epoch 46/50, Loss: 0.0015\n",
      "Epoch 47/50, Loss: 0.0041\n",
      "Epoch 48/50, Loss: 0.0018\n",
      "Epoch 49/50, Loss: 0.0010\n",
      "Epoch 50/50, Loss: 0.0023\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_aec = AutoEncoder(aec_input_dim, decoder_sigmoid=True).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model_aec.parameters(), lr=0.01, weight_decay=1e-5)\n",
    "train_ae(torch.tensor(train_data_), torch.tensor(train_labels_), aec_save_dir,\n",
    "         model_aec, criterion, optimizer, device, num_epochs=50, decoder_sigmoid=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/PRO/lib/python3.10/site-packages/torch/functional.py:632: UserWarning: stft will soon require the return_complex parameter be given for real inputs, and will further require that return_complex=True in a future PyTorch release. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:801.)\n",
      "  return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore[attr-defined]\n",
      "/root/anaconda3/envs/PRO/lib/python3.10/site-packages/torch/cuda/__init__.py:88: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 803: system has unsupported display driver / cuda driver combination (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n",
      "/root/anaconda3/envs/PRO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/root/anaconda3/envs/PRO/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:1029: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "/root/anaconda3/envs/PRO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/root/anaconda3/envs/PRO/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:1029: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "/root/anaconda3/envs/PRO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/root/anaconda3/envs/PRO/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:1029: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "/root/anaconda3/envs/PRO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/root/anaconda3/envs/PRO/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:1029: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "/root/anaconda3/envs/PRO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/root/anaconda3/envs/PRO/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:1029: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "/root/anaconda3/envs/PRO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/root/anaconda3/envs/PRO/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:1029: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metrics of attack_set/LDoS_small.csv: {'kmeans': (0.22762264838518653, 0.0, 0.0, 0.0, nan, nan, nan, nan), 'aec': (0.9780440030975265, 0.0, 0.0, 0.0, nan, nan, nan, nan), 'aew': (0.22734933722042547, 0.0, 0.0, 0.0, nan, nan, nan, nan), 'preds_majority': (0.22771375210677355, 0.0, 0.0, 0.0, nan, nan, nan, nan), 'preds_positive': (0.22589167767503301, 0.0, 0.0, 0.0, nan, nan, nan, nan), 'preds_weighted': (0.22652940372614222, 0.0, 0.0, 0.0, nan, nan, nan, nan)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/PRO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/root/anaconda3/envs/PRO/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:1029: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "/root/anaconda3/envs/PRO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/root/anaconda3/envs/PRO/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:1029: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "/root/anaconda3/envs/PRO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/root/anaconda3/envs/PRO/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:1029: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "/root/anaconda3/envs/PRO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/root/anaconda3/envs/PRO/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:1029: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "/root/anaconda3/envs/PRO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/root/anaconda3/envs/PRO/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:1029: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "/root/anaconda3/envs/PRO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/root/anaconda3/envs/PRO/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:1029: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metrics of attack_set/osscan.csv: {'kmeans': (0.9967385138967668, 0.0, 0.0, 0.0, nan, nan, nan, nan), 'aec': (0.712138400453772, 0.0, 0.0, 0.0, nan, nan, nan, nan), 'aew': (0.9958876914350538, 0.0, 0.0, 0.0, nan, nan, nan, nan), 'preds_majority': (0.9970221213840046, 0.0, 0.0, 0.0, nan, nan, nan, nan), 'preds_positive': (0.7077424844015882, 0.0, 0.0, 0.0, nan, nan, nan, nan), 'preds_weighted': (0.7097277368122519, 0.0, 0.0, 0.0, nan, nan, nan, nan)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/PRO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/root/anaconda3/envs/PRO/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:1029: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "/root/anaconda3/envs/PRO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/root/anaconda3/envs/PRO/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:1029: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "/root/anaconda3/envs/PRO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/root/anaconda3/envs/PRO/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:1029: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "/root/anaconda3/envs/PRO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/root/anaconda3/envs/PRO/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:1029: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "/root/anaconda3/envs/PRO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/root/anaconda3/envs/PRO/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:1029: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "/root/anaconda3/envs/PRO/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/root/anaconda3/envs/PRO/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:1029: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metrics of attack_set/infiltration.csv: {'kmeans': (0.99780526735834, 0.0, 0.0, 0.0, nan, nan, nan, nan), 'aec': (0.9940143655227454, 0.0, 0.0, 0.0, nan, nan, nan, nan), 'aew': (0.996608140462889, 0.0, 0.0, 0.0, nan, nan, nan, nan), 'preds_majority': (0.9982043096568236, 0.0, 0.0, 0.0, nan, nan, nan, nan), 'preds_positive': (0.9902234636871509, 0.0, 0.0, 0.0, nan, nan, nan, nan), 'preds_weighted': (0.9930167597765364, 0.0, 0.0, 0.0, nan, nan, nan, nan)}\n",
      "metrics of attack_set/HOIC_small.csv: {'kmeans': (0.6016549408378637, 0.5026702997275204, 0.9166252608566035, 0.6492802590363566, nan, nan, 0.31159614326555274, 0.8741374137413741), 'aec': (0.265270227054685, 0.0, 0.0, 0.0, nan, nan, 0.5022502250225023, 0.9954995499549955), 'aew': (0.6788055644387592, 0.6163487738419619, 0.9191385615603413, 0.7378894144511499, nan, nan, 0.2664580763253437, 0.8507350735073508), 'preds_majority': (0.6017348896706108, 0.5026702997275204, 0.9168074744061226, 0.6493259652951322, nan, nan, 0.31144612826405255, 0.8744374437443745), 'preds_positive': (0.6775263831148065, 0.6163487738419619, 0.916754478398314, 0.7371199530745918, nan, nan, 0.2688583163493461, 0.845934593459346), 'preds_weighted': (0.6008154780940198, 0.5028882833787466, 0.9143876337693222, 0.6488995148020533, nan, nan, 0.31336233895869153, 0.8703870387038704)}\n",
      "metrics of attack_set/BruteForce-Web.csv: {'kmeans': (0.9869318181818182, 0.781021897810219, 0.9596412556053812, 0.8611670020120724, nan, nan, 0.1103879723893372, 0.9982021574111066), 'aec': (0.9428030303030303, 0.0072992700729927005, 0.0625, 0.0130718954248366, nan, nan, 0.4993467692783259, 0.9940071913703555), 'aew': (0.9839015151515151, 0.7445255474452555, 0.9315068493150684, 0.8275862068965517, nan, nan, 0.12923542843478336, 0.9970035956851778), 'preds_majority': (0.9854166666666667, 0.7445255474452555, 0.966824644549763, 0.8412371134020619, nan, nan, 0.12843638728416412, 0.9986016779864163), 'preds_positive': (0.9799242424242425, 0.7846715328467153, 0.8206106870229007, 0.8022388059701492, nan, nan, 0.11235860033653049, 0.9906112664802237), 'preds_weighted': (0.9823863636363637, 0.781021897810219, 0.8663967611336032, 0.8214971209213052, nan, nan, 0.11278509584119498, 0.9934079105073911)}\n",
      "metrics of attack_set/LOIC_UDP_small.csv: {'kmeans': (0.998003992015968, 0.75, 0.25, 0.375, nan, nan, 0.1258989212944467, 0.9982021574111066), 'aec': (0.9932135728542915, 0.0, 0.0, 0.0, nan, nan, 0.5029964043148223, 0.9940071913703555), 'aew': (0.9968063872255489, 0.75, 0.16666666666666666, 0.27272727272727276, nan, nan, 0.1264982021574111, 0.9970035956851778), 'preds_majority': (0.9984031936127744, 0.75, 0.3, 0.4285714285714285, nan, nan, 0.12569916100679185, 0.9986016779864163), 'preds_positive': (0.9904191616766467, 0.75, 0.06, 0.1111111111111111, nan, nan, 0.12969436675988816, 0.9906112664802237), 'preds_weighted': (0.9932135728542915, 0.75, 0.08333333333333333, 0.15, nan, nan, 0.12829604474630446, 0.9934079105073911)}\n",
      "metrics of attack_set/SQL_Injection.csv: {'kmeans': (0.9978174603174603, 0.9411764705882353, 0.7804878048780488, 0.8533333333333334, nan, nan, 0.03031068600032904, 0.9982021574111066), 'aec': (0.9873015873015873, 0.0, 0.0, 0.0, nan, nan, 0.5029964043148223, 0.9940071913703555), 'aew': (0.9966269841269841, 0.9411764705882353, 0.6808510638297872, 0.7901234567901235, nan, nan, 0.03090996686329344, 0.9970035956851778), 'preds_majority': (0.9982142857142857, 0.9411764705882353, 0.8205128205128205, 0.8767123287671232, nan, nan, 0.0301109257126742, 0.9986016779864163), 'preds_positive': (0.9902777777777778, 0.9411764705882353, 0.4050632911392405, 0.5663716814159292, nan, nan, 0.03410613146577051, 0.9906112664802237), 'preds_weighted': (0.9930555555555556, 0.9411764705882353, 0.49230769230769234, 0.6464646464646465, nan, nan, 0.03270780945218681, 0.9934079105073911)}\n",
      "metrics of attack_set/ssldosA.csv: {'kmeans': (0.9934471803018269, 0.2, 0.4, 0.26666666666666666, nan, nan, 0.4008989212944467, 0.9982021574111066), 'aec': (0.9880857823669579, 0.0, 0.0, 0.0, nan, nan, 0.5029964043148223, 0.9940071913703555), 'aew': (0.9924543288324067, 0.23333333333333334, 0.3181818181818182, 0.2692307692307693, nan, nan, 0.38483153549074445, 0.9970035956851778), 'preds_majority': (0.993844320889595, 0.2, 0.46153846153846156, 0.27906976744186046, nan, nan, 0.40069916100679187, 0.9986016779864163), 'preds_positive': (0.9861000794281175, 0.23333333333333334, 0.12962962962962962, 0.16666666666666669, nan, nan, 0.3880277000932215, 0.9906112664802237), 'preds_weighted': (0.98868149324861, 0.2, 0.15384615384615385, 0.17391304347826086, nan, nan, 0.4032960447463045, 0.9934079105073911)}\n",
      "metrics of attack_set/fuzzscan.csv: {'kmeans': (0.5955856176575294, 0.006430868167202572, 0.7096774193548387, 0.012746234067207414, nan, nan, 0.4976834872108454, 0.9982021574111066), 'aec': (0.9806574107036905, 0.9611224788073662, 0.9909584086799277, 0.9758124350793886, nan, nan, 0.0224351649111391, 0.9940071913703555), 'aew': (0.594873620505518, 0.006430868167202572, 0.5945945945945946, 0.012724117987275881, nan, nan, 0.4982827680738098, 0.9970035956851778), 'preds_majority': (0.5958229500415332, 0.006430868167202572, 0.7586206896551724, 0.012753623188405797, nan, nan, 0.49748372692319054, 0.9986016779864163), 'preds_positive': (0.9812507416637, 0.9675533469745689, 0.9859994042299672, 0.9766892888757746, nan, nan, 0.02091769327260374, 0.9906112664802237), 'preds_weighted': (0.9829120683517266, 0.9675533469745689, 0.990128626981753, 0.9787108219988173, nan, nan, 0.019519371259020042, 0.9934079105073911)}\n",
      "metrics of attack_set/BruteForce-XSS.csv: {'kmeans': (0.9917517674783974, 0.6162790697674418, 0.8548387096774194, 0.7162162162162162, nan, nan, 0.19275938641072576, 0.9982021574111066), 'aec': (0.9772191673212883, 0.0, 0.0, 0.0, nan, nan, 0.5029964043148223, 0.9940071913703555), 'aew': (0.9899842890809112, 0.5813953488372093, 0.7692307692307693, 0.6622516556291391, nan, nan, 0.21080052773880645, 0.9970035956851778), 'preds_majority': (0.9915553809897879, 0.5813953488372093, 0.8771929824561403, 0.6993006993006993, nan, nan, 0.2100014865881872, 0.9986016779864163), 'preds_positive': (0.9842890809112333, 0.6162790697674418, 0.53, 0.5698924731182796, nan, nan, 0.19655483187616724, 0.9906112664802237), 'preds_weighted': (0.9864493322859387, 0.5813953488372093, 0.6024096385542169, 0.591715976331361, nan, nan, 0.21259837032769982, 0.9934079105073911)}\n"
     ]
    }
   ],
   "source": [
    "vote_method = \"positive\"\n",
    "\n",
    "metrics_save_dir = os.path.join(\"result\", \"ensemble\",\n",
    "                    os.path.basename(train_benign_filename))\n",
    "\n",
    "with open(\"attacker-ips.json\", \"r\") as f:\n",
    "    attack_ips_dict = json.load(f)\n",
    "\n",
    "for filename in attack_filenames:\n",
    "    benign_df = pd.read_csv(benign_filenames[0])\n",
    "    attack_df = pd.read_csv(filename)\n",
    "    test_df = pd.concat([benign_df, attack_df], ignore_index=True)\n",
    "    # test_df = pd.read_csv(filename)\n",
    "    \n",
    "    file_key = os.path.basename(filename).split(\".\")[0]\n",
    "    cur_attack_ips = attack_ips_dict.get(file_key, [])\n",
    "    test_df[\"label\"] = 0\n",
    "    for row in test_df.iterrows():\n",
    "        if row[1][\"src_ip\"] in cur_attack_ips or row[1][\"dst_ip\"] in cur_attack_ips:\n",
    "            test_df.loc[row[0], \"label\"] = -1\n",
    "        else:\n",
    "            test_df.loc[row[0], \"label\"] = 1\n",
    "\n",
    "    metrics = get_ensemble_result(test_df, USE_DATA_AUG, USE_SHORT_FLOW, \n",
    "            kmeans_save_path, aec_input_dim, aec_save_dir, aew_input_dim, \n",
    "            aew_save_dir, vote_method=vote_method)\n",
    "\n",
    "    print(f\"metrics of {filename}: {metrics}\")\n",
    "    accuracy_dict[filename] = metrics\n",
    "\n",
    "accuracy_base_name = \"flow-metrics.json\" if not USE_SHORT_FLOW else \"all-metrics.json\"\n",
    "accuracy_save_path = os.path.join(metrics_save_dir, accuracy_base_name)\n",
    "os.makedirs(os.path.dirname(accuracy_save_path), exist_ok=True)\n",
    "with open(accuracy_save_path, \"w\") as f:\n",
    "    json.dump(accuracy_dict, f, indent=4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check positive sample distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attack_set/LDoS_small.csv: total= 97750, attack= 97750, attack_ips= ['10.0.0.1', '10.0.0.4']\n",
      "attack_set/osscan.csv: total= 2337, attack= 2337, attack_ips= ['10.0.0.1', '10.0.0.4']\n",
      "attack_set/infiltration.csv: total= 3758, attack= 3758, attack_ips= ['13.58.225.34']\n",
      "attack_set/HOIC_small.csv: total= 100000, attack= 91700, attack_ips= ['18.218.115.60', '18.219.9.1', '18.219.32.43', '18.218.55.126', '52.14.136.135', '18.219.5.43', '18.216.200.189', '18.216.229.235', '18.218.11.51', '18.216.24.42']\n",
      "attack_set/BruteForce-Web.csv: total= 18252, attack= 18252, attack_ips= ['18.218.115.60']\n",
      "attack_set/LOIC_UDP_small.csv: total= 100000, attack= 100000, attack_ips= ['18.218.115.60', '18.219.9.1', '18.219.32.43', '18.218.55.126', '52.14.136.135', '18.219.5.43', '18.216.200.189', '18.216.229.235', '18.218.11.51', '18.216.24.42']\n",
      "attack_set/SQL_Injection.csv: total= 178, attack= 178, attack_ips= ['18.218.115.60']\n",
      "attack_set/ssldosA.csv: total= 100987, attack= 100987, attack_ips= ['10.0.0.1', '10.0.0.2']\n",
      "attack_set/fuzzscan.csv: total= 4197, attack= 4197, attack_ips= ['10.0.0.1', '10.0.0.3', '10.0.0.4', '10.0.0.5']\n",
      "attack_set/BruteForce-XSS.csv: total= 11699, attack= 11699, attack_ips= ['18.218.115.60']\n"
     ]
    }
   ],
   "source": [
    "with open(\"attacker-ips.json\", \"r\") as f:\n",
    "    attack_ips_dict = json.load(f)\n",
    "\n",
    "for filename in attack_filenames:\n",
    "    attack_df = pd.read_csv(filename)\n",
    "    file_key = os.path.basename(filename).split(\".\")[0]\n",
    "    cur_attack_ips = attack_ips_dict.get(file_key, [])\n",
    "    attack_packet_count = 0\n",
    "    for row in attack_df.iterrows():\n",
    "        if row[1][\"src_ip\"] in cur_attack_ips or row[1][\"dst_ip\"] in cur_attack_ips:\n",
    "            attack_packet_count += 1\n",
    "    print(f\"{filename}: total= {len(attack_df)}, attack= {attack_packet_count}, attack_ips= {cur_attack_ips}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src_ip</th>\n",
       "      <th>dst_ip</th>\n",
       "      <th>src_port</th>\n",
       "      <th>dst_port</th>\n",
       "      <th>protocol</th>\n",
       "      <th>proto_code</th>\n",
       "      <th>pkt_length</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>tos</th>\n",
       "      <th>id</th>\n",
       "      <th>ttl</th>\n",
       "      <th>chksum</th>\n",
       "      <th>flags</th>\n",
       "      <th>tcp_window</th>\n",
       "      <th>tcp_dataoffset</th>\n",
       "      <th>udp_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>172.31.69.13</td>\n",
       "      <td>13.58.225.34</td>\n",
       "      <td>50887</td>\n",
       "      <td>31337</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>1.519913e+09</td>\n",
       "      <td>2</td>\n",
       "      <td>16350</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>16384</td>\n",
       "      <td>8192</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.58.225.34</td>\n",
       "      <td>172.31.69.13</td>\n",
       "      <td>31337</td>\n",
       "      <td>50887</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>1.519913e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>23611</td>\n",
       "      <td>16384</td>\n",
       "      <td>26883</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>172.31.69.13</td>\n",
       "      <td>13.58.225.34</td>\n",
       "      <td>50887</td>\n",
       "      <td>31337</td>\n",
       "      <td>6</td>\n",
       "      <td>1000</td>\n",
       "      <td>54</td>\n",
       "      <td>1.519913e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>16351</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>16384</td>\n",
       "      <td>256</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.58.225.34</td>\n",
       "      <td>172.31.69.13</td>\n",
       "      <td>31337</td>\n",
       "      <td>50887</td>\n",
       "      <td>6</td>\n",
       "      <td>1000</td>\n",
       "      <td>58</td>\n",
       "      <td>1.519913e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>41463</td>\n",
       "      <td>63</td>\n",
       "      <td>47691</td>\n",
       "      <td>16384</td>\n",
       "      <td>211</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.58.225.34</td>\n",
       "      <td>172.31.69.13</td>\n",
       "      <td>31337</td>\n",
       "      <td>50887</td>\n",
       "      <td>6</td>\n",
       "      <td>1000</td>\n",
       "      <td>1514</td>\n",
       "      <td>1.519913e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>41464</td>\n",
       "      <td>63</td>\n",
       "      <td>46234</td>\n",
       "      <td>16384</td>\n",
       "      <td>211</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         src_ip        dst_ip  src_port  dst_port  protocol  proto_code  \\\n",
       "0  172.31.69.13  13.58.225.34     50887     31337         6           1   \n",
       "1  13.58.225.34  172.31.69.13     31337     50887         6           1   \n",
       "2  172.31.69.13  13.58.225.34     50887     31337         6        1000   \n",
       "3  13.58.225.34  172.31.69.13     31337     50887         6        1000   \n",
       "4  13.58.225.34  172.31.69.13     31337     50887         6        1000   \n",
       "\n",
       "   pkt_length     timestamp  tos     id  ttl  chksum  flags  tcp_window  \\\n",
       "0          66  1.519913e+09    2  16350  128       0  16384        8192   \n",
       "1          66  1.519913e+09    0      0   63   23611  16384       26883   \n",
       "2          54  1.519913e+09    0  16351  128       0  16384         256   \n",
       "3          58  1.519913e+09    0  41463   63   47691  16384         211   \n",
       "4        1514  1.519913e+09    0  41464   63   46234  16384         211   \n",
       "\n",
       "   tcp_dataoffset  udp_length  \n",
       "0               8         NaN  \n",
       "1               8         NaN  \n",
       "2               5         NaN  \n",
       "3               5         NaN  \n",
       "4               5         NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "infiltration_df = pd.read_csv(\"attack_set/infiltration.csv\")\n",
    "display(infiltration_df.head())\n",
    "# for row in infiltration_df.iterrows():\n",
    "#     print(row[1][\"src_ip\"], row[1][\"dst_ip\"])\n",
    "#     print (row[1][\"src_ip\"] in attack_ips_dict[\"infiltration\"] or row[1][\"dst_ip\"] in attack_ips_dict[\"infiltration\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PRO",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
