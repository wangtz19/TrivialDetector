{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble unsupervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/PRO/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from config import whisper_config\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.cluster import KMeans\n",
    "from model import AutoEncoder, Dataset, train_kmeans, test_kmeans, train_ae, test_ae, get_flows, transform\n",
    "from plot import plot_cdf, plot_line\n",
    "\n",
    "MAX_LEN = whisper_config[\"n_fft\"] * 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "benign_filenames = [os.path.join(\"train_set\", \"benign\" + str(i) + \".csv\") \n",
    "                    for i in range(1, 3)]\n",
    "attack_filenames = [os.path.join(\"attack_set\", x) for x in \n",
    "                    os.listdir(\"attack_set\") if x.endswith(\".csv\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_ensemble(datac, dataw, labels, kmeans_load_path,\n",
    "         aec_input_dim, aec_load_path, aew_input_dim, aew_load_path, \n",
    "         kmeans_scale=7, aec_scale=10, aew_scale=3,\n",
    "         test_data_aug=False, vote_method=\"majority\", plot_dir=None):\n",
    "    \n",
    "    kmeans_preds, kmeans_ratios, kmeans_loss_list = test_kmeans(dataw, kmeans_load_path, \n",
    "                                              whisper_config, scale=kmeans_scale)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    model_aec = AutoEncoder(aec_input_dim, decoder_sigmoid=True)\n",
    "    model_aec.load_state_dict(torch.load(os.path.join(aec_load_path, \"model.pt\")))\n",
    "    model_aec.to(device)\n",
    "    with open(os.path.join(aec_load_path, \"train_loss.json\"), \"r\") as f:\n",
    "        loss_list = json.load(f)\n",
    "    threshold = torch.tensor(loss_list).mean().item()\n",
    "    aec_preds, aec_ratios, aec_loss_list = test_ae(datac, model_aec, device, criterion, threshold, \n",
    "                                    scale=aec_scale, test_data_aug=False, \n",
    "                                    decoder_sigmoid=True) \n",
    "    \n",
    "    model_aew = AutoEncoder(aew_input_dim)\n",
    "    model_aew.load_state_dict(torch.load(os.path.join(aew_load_path, \"model.pt\")))\n",
    "    model_aew.to(device)\n",
    "    with open(os.path.join(aew_load_path, \"train_loss.json\"), \"r\") as f:\n",
    "        loss_list = json.load(f)\n",
    "    threshold = torch.tensor(loss_list).mean().item()\n",
    "    aew_preds, aew_ratios, aew_loss_list = test_ae(dataw, model_aew, device, criterion, threshold, \n",
    "                                    scale=aew_scale, test_data_aug=test_data_aug, \n",
    "                                    decoder_sigmoid=False)\n",
    "\n",
    "    # preds = np.sign(np.array(kmeans_preds) + np.array(aec_preds) + np.array(aew_preds))\n",
    "    preds = []\n",
    "    weights = np.array([1, 1, 1]) / 3   # kmeans, aec, aew\n",
    "    for idx in range(len(kmeans_preds)):\n",
    "        if vote_method == \"majority\":\n",
    "            preds.append(np.sign(kmeans_preds[idx] + aec_preds[idx] + aew_preds[idx]))\n",
    "        elif vote_method == \"positive\":\n",
    "            if kmeans_preds[idx] == -1 or aec_preds[idx] == -1 or aew_preds[idx] == -1:\n",
    "                preds.append(-1)\n",
    "            else:\n",
    "                preds.append(1)\n",
    "        else: # weighted\n",
    "            # tmp_preds = np.array([kmeans_preds[idx], aec_preds[idx], aew_preds[idx]])\n",
    "            # tmp_ratios = np.array([kmeans_ratios[idx], aec_ratios[idx], aew_ratios[idx]])\n",
    "            pred = np.sign(kmeans_preds[idx] * kmeans_ratios[idx] + \n",
    "                           aec_preds[idx] * aec_ratios[idx] + \n",
    "                           aew_preds[idx] * aew_ratios[idx])\n",
    "            preds.append(pred)\n",
    "\n",
    "    return {\n",
    "        \"kmeans\": accuracy_score(labels, kmeans_preds),\n",
    "        \"aec\": accuracy_score(labels, aec_preds),\n",
    "        \"aew\": accuracy_score(labels, aew_preds),\n",
    "        \"ensemble\": accuracy_score(labels, preds)\n",
    "    }, kmeans_loss_list, aec_loss_list, aew_loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ensemble_result(df_test, test_data_aug, use_short_flow, \n",
    "                        kmeans_load_path, aec_input_dim, aec_load_path, \n",
    "                        aew_input_dim, aew_load_path, vote_method=\"majority\",\n",
    "                        plot_dir=None):\n",
    "    \n",
    "    test_packet_data, test_packet_labels, test_flow_data, test_flow_labels  \\\n",
    "    = transform(get_flows(df_test), feature_type=\"encoding\" \n",
    "                ,data_type=\"test\", test_data_aug=test_data_aug)\n",
    "    data_encoding = test_flow_data if not use_short_flow else test_flow_data + test_packet_data\n",
    "    labels_encoding = test_flow_labels if not use_short_flow else test_flow_labels + test_packet_labels\n",
    "\n",
    "    test_packet_data, test_packet_labels, test_flow_data, test_flow_labels \\\n",
    "    = transform(get_flows(df_test), data_type=\"test\", test_data_aug=test_data_aug)\n",
    "    data_whisper = test_flow_data if not use_short_flow else test_flow_data + test_packet_data\n",
    "    labels_whisper = test_flow_labels if not use_short_flow else test_flow_labels + test_packet_labels\n",
    "\n",
    "    assert len(labels_encoding) == len(labels_whisper), \\\n",
    "        print(f\"len labels_encoding: {len(labels_encoding)}, len labels_whisper: {len(labels_whisper)}\")\n",
    "    for idx in range(len(labels_encoding)):\n",
    "        assert labels_encoding[idx] == labels_whisper[idx]\n",
    "    \n",
    "    acc, kmeans_loss_list, aec_loss_list, aew_loss_list = \\\n",
    "                         test_ensemble(data_encoding, data_whisper, labels_whisper, \n",
    "                        kmeans_load_path, aec_input_dim, aec_load_path, aew_input_dim, \n",
    "                        aew_load_path, test_data_aug=test_data_aug, vote_method=vote_method)\n",
    "    \n",
    "    # if plot_dir is not None:\n",
    "    #     plot_cdf(, kmeans_loss_list, \"kmeans\", plot_dir)\n",
    "\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_DATA_AUG = True\n",
    "USE_SHORT_FLOW = True\n",
    "\n",
    "accuracy_dict = {}\n",
    "suffix = \"-all\" if USE_SHORT_FLOW else \"-long\"\n",
    "train_benign_filename = \"dataset/benign_small.csv\"\n",
    "\n",
    "aec_input_dim = MAX_LEN\n",
    "aew_input_dim = whisper_config[\"n_fft\"] // 2 + 1\n",
    "kmeans_save_path = os.path.join(\"model\", \"whisper\", \"kmeans\"+suffix, \n",
    "                    os.path.basename(train_benign_filename), \"kmeans.json\")\n",
    "aec_save_dir = os.path.join(\"model\", \"autoencoding\"+suffix, \n",
    "                        os.path.basename(train_benign_filename))\n",
    "aew_save_dir = os.path.join(\"model\", \"whisper\", \"autoencoder\"+suffix, \n",
    "                        os.path.basename(train_benign_filename))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Frequency features + KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/PRO/lib/python3.10/site-packages/torch/functional.py:632: UserWarning: stft will soon require the return_complex parameter be given for real inputs, and will further require that return_complex=True in a future PyTorch release. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:801.)\n",
      "  return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(train_benign_filename)\n",
    "train_df[\"label\"] = 1\n",
    "train_packet_data, train_packet_labels, train_flow_data, train_flow_labels \\\n",
    "= transform(get_flows(train_df))\n",
    "\n",
    "train_data = train_flow_data if not USE_SHORT_FLOW else train_flow_data + train_packet_data\n",
    "train_labels = train_flow_labels if not USE_SHORT_FLOW else train_flow_labels + train_packet_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/PRO/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_kmeans(train_data, kmeans_save_path, whisper_config[\"val_K\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Frequency features + AutoEncoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 98.1166\n",
      "Epoch 2/50, Loss: 23.9330\n",
      "Epoch 3/50, Loss: 5.0799\n",
      "Epoch 4/50, Loss: 1.9488\n",
      "Epoch 5/50, Loss: 0.7033\n",
      "Epoch 6/50, Loss: 2.9570\n",
      "Epoch 7/50, Loss: 0.3255\n",
      "Epoch 8/50, Loss: 2.7003\n",
      "Epoch 9/50, Loss: 0.8728\n",
      "Epoch 10/50, Loss: 0.5623\n",
      "Epoch 11/50, Loss: 0.9623\n",
      "Epoch 12/50, Loss: 0.4802\n",
      "Epoch 13/50, Loss: 0.3182\n",
      "Epoch 14/50, Loss: 0.6932\n",
      "Epoch 15/50, Loss: 0.7875\n",
      "Epoch 16/50, Loss: 0.2908\n",
      "Epoch 17/50, Loss: 0.7281\n",
      "Epoch 18/50, Loss: 0.2246\n",
      "Epoch 19/50, Loss: 0.5675\n",
      "Epoch 20/50, Loss: 0.5423\n",
      "Epoch 21/50, Loss: 0.2764\n",
      "Epoch 22/50, Loss: 1.2582\n",
      "Epoch 23/50, Loss: 0.6044\n",
      "Epoch 24/50, Loss: 0.3076\n",
      "Epoch 25/50, Loss: 0.3734\n",
      "Epoch 26/50, Loss: 0.3808\n",
      "Epoch 27/50, Loss: 0.6041\n",
      "Epoch 28/50, Loss: 0.3547\n",
      "Epoch 29/50, Loss: 0.6665\n",
      "Epoch 30/50, Loss: 0.6599\n",
      "Epoch 31/50, Loss: 0.6247\n",
      "Epoch 32/50, Loss: 0.2840\n",
      "Epoch 33/50, Loss: 1.9269\n",
      "Epoch 34/50, Loss: 2.5784\n",
      "Epoch 35/50, Loss: 1.2231\n",
      "Epoch 36/50, Loss: 0.4141\n",
      "Epoch 37/50, Loss: 1.5400\n",
      "Epoch 38/50, Loss: 1.2441\n",
      "Epoch 39/50, Loss: 0.4358\n",
      "Epoch 40/50, Loss: 0.7861\n",
      "Epoch 41/50, Loss: 0.5995\n",
      "Epoch 42/50, Loss: 0.3244\n",
      "Epoch 43/50, Loss: 0.5051\n",
      "Epoch 44/50, Loss: 0.4406\n",
      "Epoch 45/50, Loss: 0.3123\n",
      "Epoch 46/50, Loss: 0.5339\n",
      "Epoch 47/50, Loss: 2.3186\n",
      "Epoch 48/50, Loss: 0.8083\n",
      "Epoch 49/50, Loss: 2.7487\n",
      "Epoch 50/50, Loss: 0.7312\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_aew = AutoEncoder(aew_input_dim).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model_aew.parameters(), lr=0.01, weight_decay=1e-5)\n",
    "train_ae(torch.tensor(train_data), torch.tensor(train_labels), aew_save_dir,\n",
    "         model_aew, criterion, optimizer, device, num_epochs=50)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Time features + AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(train_benign_filename)\n",
    "train_df[\"label\"] = 1\n",
    "train_packet_data_, train_packet_labels_, train_flow_data_, train_flow_labels_ \\\n",
    "= transform(get_flows(train_df), feature_type=\"encoding\")\n",
    "\n",
    "train_data_ = train_flow_data_ if not USE_SHORT_FLOW else train_flow_data_ + train_packet_data_\n",
    "train_labels_ = train_flow_labels_ if not USE_SHORT_FLOW else train_flow_labels_ + train_packet_labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 0.0816\n",
      "Epoch 2/50, Loss: 0.0461\n",
      "Epoch 3/50, Loss: 0.0254\n",
      "Epoch 4/50, Loss: 0.0206\n",
      "Epoch 5/50, Loss: 0.0150\n",
      "Epoch 6/50, Loss: 0.0207\n",
      "Epoch 7/50, Loss: 0.0185\n",
      "Epoch 8/50, Loss: 0.0141\n",
      "Epoch 9/50, Loss: 0.0125\n",
      "Epoch 10/50, Loss: 0.0024\n",
      "Epoch 11/50, Loss: 0.0128\n",
      "Epoch 12/50, Loss: 0.0070\n",
      "Epoch 13/50, Loss: 0.0020\n",
      "Epoch 14/50, Loss: 0.0052\n",
      "Epoch 15/50, Loss: 0.0029\n",
      "Epoch 16/50, Loss: 0.0031\n",
      "Epoch 17/50, Loss: 0.0041\n",
      "Epoch 18/50, Loss: 0.0047\n",
      "Epoch 19/50, Loss: 0.0039\n",
      "Epoch 20/50, Loss: 0.0037\n",
      "Epoch 21/50, Loss: 0.0063\n",
      "Epoch 22/50, Loss: 0.0057\n",
      "Epoch 23/50, Loss: 0.0041\n",
      "Epoch 24/50, Loss: 0.0017\n",
      "Epoch 25/50, Loss: 0.0058\n",
      "Epoch 26/50, Loss: 0.0083\n",
      "Epoch 27/50, Loss: 0.0056\n",
      "Epoch 28/50, Loss: 0.0073\n",
      "Epoch 29/50, Loss: 0.0030\n",
      "Epoch 30/50, Loss: 0.0017\n",
      "Epoch 31/50, Loss: 0.0021\n",
      "Epoch 32/50, Loss: 0.0029\n",
      "Epoch 33/50, Loss: 0.0051\n",
      "Epoch 34/50, Loss: 0.0014\n",
      "Epoch 35/50, Loss: 0.0028\n",
      "Epoch 36/50, Loss: 0.0044\n",
      "Epoch 37/50, Loss: 0.0027\n",
      "Epoch 38/50, Loss: 0.0003\n",
      "Epoch 39/50, Loss: 0.0013\n",
      "Epoch 40/50, Loss: 0.0018\n",
      "Epoch 41/50, Loss: 0.0039\n",
      "Epoch 42/50, Loss: 0.0004\n",
      "Epoch 43/50, Loss: 0.0038\n",
      "Epoch 44/50, Loss: 0.0059\n",
      "Epoch 45/50, Loss: 0.0023\n",
      "Epoch 46/50, Loss: 0.0015\n",
      "Epoch 47/50, Loss: 0.0041\n",
      "Epoch 48/50, Loss: 0.0018\n",
      "Epoch 49/50, Loss: 0.0010\n",
      "Epoch 50/50, Loss: 0.0023\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_aec = AutoEncoder(aec_input_dim, decoder_sigmoid=True).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model_aec.parameters(), lr=0.01, weight_decay=1e-5)\n",
    "train_ae(torch.tensor(train_data_), torch.tensor(train_labels_), aec_save_dir,\n",
    "         model_aec, criterion, optimizer, device, num_epochs=50, decoder_sigmoid=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of train_set/benign1.csv: {'kmeans': 0.9982021574111066, 'aec': 0.9940071913703555, 'aew': 0.9970035956851778, 'ensemble': 0.9906112664802237}\n",
      "accuracy of train_set/benign2.csv: {'kmeans': 0.9984387197501952, 'aec': 0.9923887587822015, 'aew': 0.997072599531616, 'ensemble': 0.9892661982825918}\n",
      "accuracy of attack_set/LDoS_small.csv: {'kmeans': 1.0, 'aec': 0.026671387266182806, 'aew': 1.0, 'ensemble': 1.0}\n",
      "accuracy of attack_set/SYNDoS.csv: {'kmeans': 0.0, 'aec': 0.0, 'aew': 0.0, 'ensemble': 0.0}\n",
      "accuracy of attack_set/osscan.csv: {'kmeans': 0.006842619745845552, 'aec': 0.9775171065493646, 'aew': 0.006842619745845552, 'ensemble': 0.9843597262952102}\n",
      "accuracy of attack_set/infiltration.csv: {'kmeans': 0.3333333333333333, 'aec': 0.0, 'aew': 0.3333333333333333, 'ensemble': 0.3333333333333333}\n",
      "accuracy of attack_set/HOIC_small.csv: {'kmeans': 0.5024487756121939, 'aec': 0.0, 'aew': 0.6141929035482259, 'ensemble': 0.6141929035482259}\n",
      "accuracy of attack_set/BruteForce-Web.csv: {'kmeans': 0.781021897810219, 'aec': 0.0072992700729927005, 'aew': 0.7445255474452555, 'ensemble': 0.7846715328467153}\n",
      "accuracy of attack_set/LOIC_UDP_small.csv: {'kmeans': 0.75, 'aec': 0.0, 'aew': 0.75, 'ensemble': 0.75}\n",
      "accuracy of attack_set/SQL_Injection.csv: {'kmeans': 0.9411764705882353, 'aec': 0.0, 'aew': 0.9411764705882353, 'ensemble': 0.9411764705882353}\n",
      "accuracy of attack_set/ssldosA.csv: {'kmeans': 0.2, 'aec': 0.0, 'aew': 0.23333333333333334, 'ensemble': 0.23333333333333334}\n",
      "accuracy of attack_set/SYNDoS_small.csv: {'kmeans': 0.0, 'aec': 0.47411346435546875, 'aew': 0.0, 'ensemble': 0.47411346435546875}\n",
      "accuracy of attack_set/fuzzscan.csv: {'kmeans': 0.006430868167202572, 'aec': 0.9611224788073662, 'aew': 0.006430868167202572, 'ensemble': 0.9675533469745689}\n",
      "accuracy of attack_set/BruteForce-XSS.csv: {'kmeans': 0.6162790697674418, 'aec': 0.0, 'aew': 0.5813953488372093, 'ensemble': 0.6162790697674418}\n"
     ]
    }
   ],
   "source": [
    "vote_method = \"positive\"\n",
    "\n",
    "accuracy_save_dir = os.path.join(\"result\", \"ensemble\", vote_method,\n",
    "                    os.path.basename(train_benign_filename))\n",
    "\n",
    "for filename in benign_filenames + attack_filenames:\n",
    "    test_df = pd.read_csv(filename)\n",
    "    test_df[\"label\"] = 1 if filename in benign_filenames else -1\n",
    "    acc = get_ensemble_result(test_df, USE_DATA_AUG, USE_SHORT_FLOW, \n",
    "            kmeans_save_path, aec_input_dim, aec_save_dir, aew_input_dim, \n",
    "            aew_save_dir, vote_method=vote_method)\n",
    "\n",
    "    print(f\"accuracy of {filename}: {acc}\")\n",
    "    accuracy_dict[filename] = acc\n",
    "\n",
    "accuracy_base_name = \"flow-accuracy.json\" if not USE_SHORT_FLOW else \"all-accuracy.json\"\n",
    "accuracy_save_path = os.path.join(accuracy_save_dir, accuracy_base_name)\n",
    "os.makedirs(os.path.dirname(accuracy_save_path), exist_ok=True)\n",
    "with open(accuracy_save_path, \"w\") as f:\n",
    "    json.dump(accuracy_dict, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PRO",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
