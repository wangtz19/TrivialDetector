{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract flow level features by Whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/PRO/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from utils import Packet, Flow\n",
    "from config import whisper_config\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_flows(df: pd.DataFrame, key_type: str = \"default\") -> dict:\n",
    "    mp = dict()\n",
    "    for idx in range(len(df)): # simulate the process of packet processing\n",
    "        row = df.iloc[idx]\n",
    "        pkt = Packet(\n",
    "            src_ip=row[\"src_ip\"],\n",
    "            dst_ip=row[\"dst_ip\"],\n",
    "            src_port=row[\"src_port\"],\n",
    "            dst_port=row[\"dst_port\"],\n",
    "            protocol=row[\"protocol\"],\n",
    "            proto_code=row[\"proto_code\"],\n",
    "            pkt_length=row[\"pkt_length\"],\n",
    "            timestamp=row[\"timestamp\"],\n",
    "            ttl=row[\"ttl\"],\n",
    "            tcp_window=row[\"tcp_window\"],\n",
    "            tcp_dataoffset=row[\"tcp_dataoffset\"],\n",
    "            udp_length=row[\"udp_length\"],\n",
    "            label=row[\"label\"],\n",
    "        )\n",
    "        key = pkt.key(type=key_type)\n",
    "        if key not in mp:\n",
    "            mp[key] = Flow()\n",
    "        mp[key].add_packet(pkt)\n",
    "    return mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(mp: dict, feature_type: str = \"whisper\", \n",
    "              data_type: str = \"train\", test_data_aug: bool = True):\n",
    "    packet_data, flow_data = [], []\n",
    "    packet_labels, flow_labels = [], []\n",
    "    for key, flow in mp.items():\n",
    "        vec = flow.vector(feature_type=feature_type)\n",
    "        if feature_type == \"whisper\":\n",
    "            if len(vec) <= (whisper_config[\"n_fft\"] // 2):\n",
    "                # packet level features\n",
    "                # vec = flow.packet_vector(agg_type=\"mean\") + flow.packet_vector(agg_type=\"std\") \\\n",
    "                #     + flow.packet_vector(agg_type=\"max\") + flow.packet_vector(agg_type=\"min\")\n",
    "                # packet_data.append(vec)\n",
    "                # packet_labels.append(flow.label)\n",
    "\n",
    "                # implement fft on short flows\n",
    "                ten = torch.tensor(vec)\n",
    "                ten_fft = torch.fft.fft(ten, n=(whisper_config[\"n_fft\"] // 2)+1)\n",
    "                ten_power = torch.pow(ten_fft.real, 2) + torch.pow(ten_fft.imag, 2)\n",
    "                ten_res = (ten_power.squeeze()+1).log2()\n",
    "                ten_res = torch.where(torch.isnan(ten_res), torch.zeros_like(ten_res), ten_res)\n",
    "                ten_res = torch.where(torch.isinf(ten_res), torch.zeros_like(ten_res), ten_res)\n",
    "                if data_type == \"test\" and test_data_aug:\n",
    "                    # data shape for test data augmentation: (n_flow, n_sample, floor(n_fft/2)+1)\n",
    "                    packet_data.append([ten_res.tolist()])\n",
    "                else:\n",
    "                    # data shape for no data augmentation: (n_flow, floor(n_fft/2)+1)\n",
    "                    packet_data.append(ten_res.tolist())\n",
    "                packet_labels.append(flow.label)\n",
    "                \n",
    "            else:\n",
    "                # flow level featrues\n",
    "                ten = torch.tensor(vec)\n",
    "                # stft requirement: input_size > (n_fft // 2)\n",
    "                # default return shape: (floor(n_fft/2)+1, n_frame, 2)\n",
    "                ten_fft = torch.stft(ten, whisper_config[\"n_fft\"])\n",
    "                ten_power = torch.pow(ten_fft[:,:,0], 2) + torch.pow(ten_fft[:,:,1], 2)\n",
    "                ten_res = ((ten_power.squeeze()+1).log2()).permute(1,0)\n",
    "                ten_res = torch.where(torch.isnan(ten_res), torch.zeros_like(ten_res), ten_res)\n",
    "                ten_res = torch.where(torch.isinf(ten_res), torch.zeros_like(ten_res), ten_res)\n",
    "                # ten_res shape: (n_frame, floor(n_fft/2)+1)\n",
    "                if data_type == \"train\":\n",
    "                    if (ten_res.size(0) > whisper_config[\"mean_win_train\"]):\n",
    "                        for _ in range(whisper_config[\"num_train_sample\"]):\n",
    "                            start_idx = torch.randint(0, ten_res.size(0)\n",
    "                                        - whisper_config[\"mean_win_train\"], (1,)).item()\n",
    "                            ten_tmp = ten_res[start_idx:start_idx+whisper_config[\"mean_win_train\"],:].mean(dim=0)\n",
    "                            flow_data.append(ten_tmp.tolist())\n",
    "                    else:\n",
    "                        flow_data.append(ten_res.mean(dim=0).tolist())\n",
    "                else: # for test\n",
    "                    if test_data_aug:\n",
    "                        tmp_data = []\n",
    "                        if (ten_res.size(0) > whisper_config[\"mean_win_test\"]):\n",
    "                            # data augmentation for kmeans on flows with length > mean_win_test\n",
    "                            for idx in range(0, ten_res.size(0) - whisper_config[\"mean_win_test\"], \n",
    "                                            whisper_config[\"mean_win_test\"]):\n",
    "                                ten_tmp = ten_res[idx:idx+whisper_config[\"mean_win_test\"],:].mean(dim=0)\n",
    "                                tmp_data.append(ten_tmp.tolist())\n",
    "                        else:\n",
    "                            # no data augmentation for kmeans on flows with length < mean_win_test\n",
    "                            tmp_data.append(ten_res.mean(dim=0).tolist())\n",
    "                        flow_data.append(tmp_data)\n",
    "                        # data shape for augmentation: (n_flow, n_sample, floor(n_fft/2)+1)\n",
    "                    else: # for other detection methods\n",
    "                        flow_data.append(ten_res.mean(dim=0).tolist())\n",
    "                        # data shape for no augmentation: (n_flow, floor(n_fft/2)+1)\n",
    "                flow_labels.append(flow.label)\n",
    "        elif feature_type == \"encoding\":\n",
    "            # directly use the whisper encoding vector\n",
    "            pass\n",
    "        else: # for other feature types\n",
    "            pass\n",
    "    return packet_data, packet_labels, flow_data, flow_labels"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train & test with unsupervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_kmeans(train_data, save_path, n_clusters):\n",
    "    train_data = torch.tensor(train_data)\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=0)\n",
    "    kmeans.fit(train_data.cpu().numpy())\n",
    "\n",
    "    centroids = torch.tensor(kmeans.cluster_centers_)\n",
    "    train_loss = torch.cdist(train_data, centroids, p=2).min(dim=1).values.mean()\n",
    "\n",
    "    if not os.path.exists(os.path.dirname(save_path)):\n",
    "        os.makedirs(os.path.dirname(save_path))\n",
    "    with open(save_path, \"w\") as f:\n",
    "        json.dump({\n",
    "            \"centroids\": centroids.tolist(),\n",
    "            \"train_loss\": train_loss.item(),\n",
    "        }, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_kmeans(test_data, test_labels, load_path, scale=5):\n",
    "    with open(load_path, \"r\") as f:\n",
    "        model_param = json.load(f)\n",
    "    centroids = torch.tensor(model_param[\"centroids\"])\n",
    "    train_loss = model_param[\"train_loss\"]\n",
    "    \n",
    "    pred = []\n",
    "    for val in test_data:\n",
    "        val = torch.tensor(val)\n",
    "        if (val.size(0) > whisper_config[\"mean_win_test\"]):\n",
    "            max_dist = 0\n",
    "            for idx in range(0, val.size(0) - whisper_config[\"mean_win_test\"], \n",
    "                             whisper_config[\"mean_win_test\"]):\n",
    "                ten_tmp = val[idx:idx+whisper_config[\"mean_win_test\"],:].mean(dim=0)\n",
    "                dist = torch.norm(ten_tmp - centroids, dim=1).min()\n",
    "                max_dist = max(max_dist, dist)\n",
    "            min_dist = max_dist\n",
    "        else:\n",
    "            min_dist = torch.norm(val.mean(dim=0) - centroids, dim=1).min()\n",
    "        pred.append(-1 if min_dist > scale * train_loss else 1)\n",
    "    return accuracy_score(test_labels, pred)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "benign_filenames = [os.path.join(\"train_set\", \"benign\" + str(i) + \".csv\") \n",
    "                    for i in range(1, 3)]\n",
    "attack_filenames = [os.path.join(\"attack_set\", x) for x in \n",
    "                    os.listdir(\"attack_set\") if x.endswith(\".csv\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_SHORT_FLOW = True\n",
    "scale = 7\n",
    "\n",
    "# train_benign_filename = benign_filenames[0]\n",
    "# train_benign_filename = os.path.join(\"dataset_lite\", \"mirai-benign.csv\")\n",
    "train_benign_filename = \"dataset/benign_small.csv\"\n",
    "base_name = \"flow-kmeans.json\" if not USE_SHORT_FLOW else \"all-kmeans.json\"\n",
    "save_path = os.path.join(\"model\", \"whisper\", \"kmeans\", os.path.basename(train_benign_filename), base_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/PRO/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(train_benign_filename)\n",
    "train_df[\"label\"] = \"unknown\"\n",
    "train_packet_data, train_packet_labels, train_flow_data, train_flow_labels = transform(get_flows(train_df))\n",
    "\n",
    "train_data = train_flow_data if not USE_SHORT_FLOW else train_flow_data + train_packet_data\n",
    "train_kmeans(train_data, save_path, whisper_config[\"val_K\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of train_set/benign1.csv: 0.9982021574111066\n",
      "accuracy of train_set/benign2.csv: 0.9984387197501952\n",
      "accuracy of attack_set/LDoS_small.csv: 0.0\n",
      "accuracy of attack_set/osscan.csv: 0.006842619745845552\n",
      "accuracy of attack_set/infiltration.csv: 0.3333333333333333\n",
      "accuracy of attack_set/HOIC_small.csv: 0.5058723531911702\n",
      "accuracy of attack_set/BruteForce-Web.csv: 0.781021897810219\n",
      "accuracy of attack_set/LOIC_UDP_small.csv: 0.88\n",
      "accuracy of attack_set/SQL_Injection.csv: 0.9411764705882353\n",
      "accuracy of attack_set/ssldosA.csv: 0.23333333333333334\n",
      "accuracy of attack_set/fuzzscan.csv: 0.006430868167202572\n",
      "accuracy of attack_set/BruteForce-XSS.csv: 0.6395348837209303\n"
     ]
    }
   ],
   "source": [
    "USE_DATA_AUG = True\n",
    "detect_type = \"kmeans\" if USE_DATA_AUG else \"kmeans-no-aug\"\n",
    "\n",
    "accuracy_dict = {}\n",
    "\n",
    "for test_benign_filename in benign_filenames:\n",
    "    test_df = pd.read_csv(test_benign_filename)\n",
    "    test_df[\"label\"] = 1\n",
    "    test_packet_data, test_packet_lables, test_flow_data, test_flow_labels \\\n",
    "    = transform(get_flows(test_df), data_type=\"test\", test_data_aug=USE_DATA_AUG)\n",
    "    test_data = test_flow_data if not USE_SHORT_FLOW else test_flow_data + test_packet_data\n",
    "    test_labels = test_flow_labels if not USE_SHORT_FLOW else test_flow_labels + test_packet_lables\n",
    "    acc = test_kmeans(test_data, test_labels, save_path, scale=scale)\n",
    "    print(f\"accuracy of {test_benign_filename}: {acc}\")\n",
    "    accuracy_dict[test_benign_filename] = acc\n",
    "\n",
    "for test_attack_filename in attack_filenames:\n",
    "    test_df = pd.read_csv(test_attack_filename)\n",
    "    test_df[\"label\"] = -1\n",
    "    test_packet_data, test_packet_lables, test_flow_data, test_flow_labels \\\n",
    "    = transform(get_flows(test_df), data_type=\"test\", test_data_aug=USE_DATA_AUG)\n",
    "    test_data = test_flow_data if not USE_SHORT_FLOW else test_flow_data + test_packet_data\n",
    "    test_labels = test_flow_labels if not USE_SHORT_FLOW else test_flow_labels + test_packet_lables\n",
    "    acc = test_kmeans(test_data, test_labels, save_path, scale=scale)\n",
    "    print(f\"accuracy of {test_attack_filename}: {acc}\")\n",
    "    accuracy_dict[test_attack_filename] = acc\n",
    "\n",
    "accuracy_base_name = \"flow-accuracy.json\" if not USE_SHORT_FLOW else \"all-accuracy.json\"\n",
    "accuracy_save_path = os.path.join(\"result\", \"whisper\", detect_type, \n",
    "                    os.path.basename(train_benign_filename), str(scale)+\"-\"+accuracy_base_name)\n",
    "os.makedirs(os.path.dirname(accuracy_save_path), exist_ok=True)\n",
    "with open(accuracy_save_path, \"w\") as f:\n",
    "    json.dump(accuracy_dict, f, indent=4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mix benign and attack traffic during testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mix_df(benign_path: str = None, attack_path: str = None):\n",
    "    assert benign_path is not None or attack_path is not None, \\\n",
    "        \"benign_path and attack_path cannot be None at the same time\"\n",
    "    if benign_path is not None:\n",
    "        df_benign = pd.read_csv(benign_path)\n",
    "        df_benign[\"label\"] = 1\n",
    "    else:\n",
    "        df_benign = None\n",
    "    if attack_path is not None:\n",
    "        df_attack = pd.read_csv(attack_path)\n",
    "        df_attack[\"label\"] = -1\n",
    "    else:\n",
    "        df_attack = None\n",
    "    df_mix = pd.concat([df_benign, df_attack], ignore_index=True, axis=0)\n",
    "    return df_mix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of dataset_lite/BruteForce-Web.csv: 0.9740530303030303\n",
      "accuracy of dataset_lite/BruteForce-XSS.csv: 0.9844854673998429\n",
      "accuracy of dataset_lite/infiltration.csv: 0.9990023942537909\n",
      "accuracy of dataset_lite/osscan.csv: 0.7107203630175837\n",
      "accuracy of dataset_lite/SQL_Injection.csv: 0.9968253968253968\n",
      "accuracy of dataset_lite/ssldosA10only.csv: 0.9954265261483396\n",
      "accuracy of dataset_lite/mirai-attack.csv: 0.1684800747613644\n"
     ]
    }
   ],
   "source": [
    "USE_DATA_AUG = True\n",
    "detect_type = \"kmeans\" if USE_DATA_AUG else \"kmeans-no-aug\"\n",
    "\n",
    "accuracy_dict = {}\n",
    "test_benign_filename = benign_filenames[0]\n",
    "\n",
    "for test_attack_filename in attack_filenames:\n",
    "    test_df = get_mix_df(benign_path=test_benign_filename, \n",
    "                         attack_path=test_attack_filename)\n",
    "    test_packet_data, test_packet_lables, test_flow_data, test_flow_labels \\\n",
    "    = transform(get_flows(test_df), data_type=\"test\", test_data_aug=USE_DATA_AUG)\n",
    "    test_data = test_flow_data if not USE_SHORT_FLOW else test_flow_data + test_packet_data\n",
    "    test_labels = test_flow_labels if not USE_SHORT_FLOW else test_flow_labels + test_packet_lables\n",
    "    acc = test_kmeans(test_data, test_labels, save_path, scale=10)\n",
    "    print(f\"accuracy of {test_attack_filename}: {acc}\")\n",
    "    accuracy_dict[test_benign_filename+\"-\"+test_attack_filename] = acc\n",
    "\n",
    "accuracy_base_name = \"flow-mix-accuracy.json\" if not USE_SHORT_FLOW else \"all-mix-accuracy.json\"\n",
    "accuracy_save_path = os.path.join(\"result\", \"whisper\", detect_type, \n",
    "                    os.path.basename(train_benign_filename), accuracy_base_name)\n",
    "os.makedirs(os.path.dirname(accuracy_save_path), exist_ok=True)\n",
    "with open(accuracy_save_path, \"w\") as f:\n",
    "    json.dump(accuracy_dict, f, indent=4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and test LOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "import skops.io as sio\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def train_lof(data, save_path):\n",
    "    clf = LocalOutlierFactor(novelty=True)\n",
    "    clf.fit(data)\n",
    "    if not os.path.exists(os.path.dirname(save_path)):\n",
    "        os.makedirs(os.path.dirname(save_path))\n",
    "    sio.dump(clf, save_path)\n",
    "\n",
    "def test_lof(data, labels, load_path, test_data_aug=False):\n",
    "    clf = sio.load(load_path)\n",
    "    if not test_data_aug:\n",
    "        preds = clf.predict(data)\n",
    "    else:\n",
    "        preds = []\n",
    "        for val in data:\n",
    "            pred = clf.predict(val)\n",
    "            preds.append(1 if sum(pred) > -1*len(pred) else -1)\n",
    "    return accuracy_score(labels, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "USE_SHORT_FLOW = True\n",
    "\n",
    "# train_benign_filename = benign_filenames[0]\n",
    "# train_benign_filename = os.path.join(\"dataset_lite\", \"mirai-benign.csv\")\n",
    "train_benign_filename = \"dataset/benign_small.csv\"\n",
    "train_df = pd.read_csv(train_benign_filename)\n",
    "train_df[\"label\"] = \"unknown\"\n",
    "train_packet_data, train_packet_labels, train_flow_data, train_flow_labels = transform(get_flows(train_df))\n",
    "\n",
    "base_name = \"flow-lof.skops\" if not USE_SHORT_FLOW else \"all-lof.skops\"\n",
    "save_path = os.path.join(\"model\", \"whisper\", \"lof\", os.path.basename(train_benign_filename), base_name)\n",
    "train_data = train_flow_data if not USE_SHORT_FLOW else train_flow_data + train_packet_data\n",
    "train_lof(train_data, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of train_set/benign1.csv: 0.18318018377946466\n",
      "accuracy of train_set/benign2.csv: 0.23341139734582358\n",
      "accuracy of dataset_lite/BruteForce-Web.csv: 1.0\n",
      "accuracy of dataset_lite/BruteForce-XSS.csv: 1.0\n",
      "accuracy of dataset_lite/infiltration.csv: 1.0\n",
      "accuracy of dataset_lite/osscan.csv: 0.9965786901270772\n",
      "accuracy of dataset_lite/SQL_Injection.csv: 1.0\n",
      "accuracy of dataset_lite/ssldosA10only.csv: 0.30434782608695654\n",
      "accuracy of dataset_lite/mirai-attack.csv: 0.880629908639205\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "USE_DATA_AUG = True\n",
    "detect_type = \"lof\" if USE_DATA_AUG else \"lof-no-aug\"\n",
    "\n",
    "accuracy_dict = {}\n",
    "\n",
    "for test_benign_filename in benign_filenames[:2]:\n",
    "    test_df = pd.read_csv(test_benign_filename)\n",
    "    test_df[\"label\"] = 1\n",
    "    test_packet_data, test_packet_lables, test_flow_data, test_flow_labels \\\n",
    "        = transform(get_flows(test_df), data_type=\"test\", test_data_aug=USE_DATA_AUG)\n",
    "    test_data = test_flow_data if not USE_SHORT_FLOW else test_flow_data + test_packet_data\n",
    "    test_labels = test_flow_labels if not USE_SHORT_FLOW else test_flow_labels + test_packet_lables\n",
    "    acc = test_lof(test_data, test_labels, save_path, test_data_aug=USE_DATA_AUG)\n",
    "    print(f\"accuracy of {test_benign_filename}: {acc}\")\n",
    "    accuracy_dict[test_benign_filename] = acc\n",
    "\n",
    "for test_attack_filename in attack_filenames:\n",
    "    test_df = pd.read_csv(test_attack_filename)\n",
    "    test_df[\"label\"] = -1\n",
    "    test_packet_data, test_packet_lables, test_flow_data, test_flow_labels \\\n",
    "        = transform(get_flows(test_df), data_type=\"test\", test_data_aug=USE_DATA_AUG)\n",
    "    test_data = test_flow_data if not USE_SHORT_FLOW else test_flow_data + test_packet_data\n",
    "    test_labels = test_flow_labels if not USE_SHORT_FLOW else test_flow_labels + test_packet_lables\n",
    "    if len(test_data) > 0:\n",
    "        acc = test_lof(test_data, test_labels, save_path, test_data_aug=USE_DATA_AUG)\n",
    "    else:\n",
    "        acc = np.nan\n",
    "    print(f\"accuracy of {test_attack_filename}: {acc}\")\n",
    "    accuracy_dict[test_attack_filename] = acc\n",
    "\n",
    "accuracy_base_name = \"flow-accuracy.json\" if not USE_SHORT_FLOW else \"all-accuracy.json\"\n",
    "accuracy_save_path = os.path.join(\"result\", \"whisper\", detect_type, os.path.basename(train_benign_filename), accuracy_base_name)\n",
    "os.makedirs(os.path.dirname(accuracy_save_path), exist_ok=True)\n",
    "with open(accuracy_save_path, \"w\") as f:\n",
    "    json.dump(accuracy_dict, f, indent=4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and test SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import OneClassSVM\n",
    "import skops.io as sio\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def train_svm(data, save_path):\n",
    "    clf = OneClassSVM(kernel=\"rbf\", nu=0.1)\n",
    "    clf.fit(data)\n",
    "    if not os.path.exists(os.path.dirname(save_path)):\n",
    "        os.makedirs(os.path.dirname(save_path))\n",
    "    sio.dump(clf, save_path)\n",
    "\n",
    "def test_svm(data, labels, load_path, test_data_aug=False):\n",
    "    clf = sio.load(load_path)\n",
    "    if not test_data_aug:\n",
    "        preds = clf.predict(data)\n",
    "    else:\n",
    "        preds = []\n",
    "        for val in data:\n",
    "            pred = clf.predict(val)\n",
    "            preds.append(1 if sum(pred) > -1*len(pred) else -1)\n",
    "    return accuracy_score(labels, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "USE_SHORT_FLOW = True\n",
    "\n",
    "# train_benign_filename = benign_filenames[0]\n",
    "# train_benign_filename = os.path.join(\"dataset_lite\", \"mirai-benign.csv\")\n",
    "train_benign_filename = \"dataset/benign_small.csv\"\n",
    "train_df = pd.read_csv(train_benign_filename)\n",
    "train_df[\"label\"] = \"unknown\"\n",
    "train_packet_data, train_packet_labels, train_flow_data, train_flow_labels = transform(get_flows(train_df))\n",
    "\n",
    "base_name = \"flow-svm.skops\" if not USE_SHORT_FLOW else \"all-svm.skops\"\n",
    "save_path = os.path.join(\"model\", \"whisper\", \"svm\", os.path.basename(train_benign_filename), base_name)\n",
    "train_data = train_flow_data if not USE_SHORT_FLOW else train_flow_data + train_packet_data\n",
    "train_lof(train_data, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of train_set/benign1.csv: 0.18457850579304835\n",
      "accuracy of train_set/benign2.csv: 0.23341139734582358\n",
      "accuracy of dataset_lite/BruteForce-Web.csv: 1.0\n",
      "accuracy of dataset_lite/BruteForce-XSS.csv: 1.0\n",
      "accuracy of dataset_lite/infiltration.csv: 1.0\n",
      "accuracy of dataset_lite/osscan.csv: 0.9965786901270772\n",
      "accuracy of dataset_lite/SQL_Injection.csv: 1.0\n",
      "accuracy of dataset_lite/ssldosA10only.csv: 0.30434782608695654\n",
      "accuracy of dataset_lite/mirai-attack.csv: 0.8807501202115724\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "USE_DATA_AUG = True\n",
    "detect_type = \"svm\" if USE_DATA_AUG else \"svm-no-aug\"\n",
    "\n",
    "accuracy_dict = {}\n",
    "\n",
    "for test_benign_filename in benign_filenames[:2]:\n",
    "    test_df = pd.read_csv(test_benign_filename)\n",
    "    test_df[\"label\"] = 1\n",
    "    test_packet_data, test_packet_lables, test_flow_data, test_flow_labels \\\n",
    "        = transform(get_flows(test_df), data_type=\"test\", test_data_aug=USE_DATA_AUG)\n",
    "    test_data = test_flow_data if not USE_SHORT_FLOW else test_flow_data + test_packet_data\n",
    "    test_labels = test_flow_labels if not USE_SHORT_FLOW else test_flow_labels + test_packet_lables\n",
    "    acc = test_svm(test_data, test_labels, save_path, test_data_aug=USE_DATA_AUG)\n",
    "    print(f\"accuracy of {test_benign_filename}: {acc}\")\n",
    "    accuracy_dict[test_benign_filename] = acc\n",
    "\n",
    "for test_attack_filename in attack_filenames:\n",
    "    test_df = pd.read_csv(test_attack_filename)\n",
    "    test_df[\"label\"] = -1\n",
    "    test_packet_data, test_packet_lables, test_flow_data, test_flow_labels \\\n",
    "        = transform(get_flows(test_df), data_type=\"test\", test_data_aug=USE_DATA_AUG)\n",
    "    test_data = test_flow_data if not USE_SHORT_FLOW else test_flow_data + test_packet_data\n",
    "    test_labels = test_flow_labels if not USE_SHORT_FLOW else test_flow_labels + test_packet_lables\n",
    "    if len(test_data) > 0:\n",
    "        acc = test_svm(test_data, test_labels, save_path, test_data_aug=USE_DATA_AUG)\n",
    "    else:\n",
    "        acc = np.nan\n",
    "    print(f\"accuracy of {test_attack_filename}: {acc}\")\n",
    "    accuracy_dict[test_attack_filename] = acc\n",
    "\n",
    "accuracy_base_name = \"flow-accuracy.json\" if not USE_SHORT_FLOW else \"all-accuracy.json\"\n",
    "accuracy_save_path = os.path.join(\"result\", \"whisper\", detect_type, os.path.basename(train_benign_filename), accuracy_base_name)\n",
    "os.makedirs(os.path.dirname(accuracy_save_path), exist_ok=True)\n",
    "with open(accuracy_save_path, \"w\") as f:\n",
    "    json.dump(accuracy_dict, f, indent=4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and test ensemble detectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "\n",
    "def train_kmeans(train_data, save_path, n_clusters):\n",
    "    train_data = torch.tensor(train_data)\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=0)\n",
    "    kmeans.fit(train_data.cpu().numpy())\n",
    "\n",
    "    centroids = torch.tensor(kmeans.cluster_centers_)\n",
    "    train_loss = torch.cdist(train_data, centroids, p=2).min(dim=1).values.mean()\n",
    "\n",
    "    if not os.path.exists(os.path.dirname(save_path)):\n",
    "        os.makedirs(os.path.dirname(save_path))\n",
    "    with open(save_path, \"w\") as f:\n",
    "        json.dump({\n",
    "            \"centroids\": centroids.tolist(),\n",
    "            \"train_loss\": train_loss.item(),\n",
    "        }, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PRO",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
