{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compare time intervals of different attack types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attack_set/LDoS_small.csv time interval mean: 0.3006698918581009\n",
      "attack_set/LDoS_small.csv time interval std: 0.11745484057654854\n",
      "attack_set/LDoS_small.csv time interval max: 0.37209105491638184\n",
      "attack_set/LDoS_small.csv time interval min: 0.0\n",
      "attack_set/osscan.csv time interval mean: 0.11535976605431844\n",
      "attack_set/osscan.csv time interval std: 0.5495557577423145\n",
      "attack_set/osscan.csv time interval max: 3.77128005027771\n",
      "attack_set/osscan.csv time interval min: 0.0\n",
      "attack_set/infiltration.csv time interval mean: 10.637729452860489\n",
      "attack_set/infiltration.csv time interval std: 22.320994515466953\n",
      "attack_set/infiltration.csv time interval max: 84.10361289978027\n",
      "attack_set/infiltration.csv time interval min: 0.0\n",
      "attack_set/HOIC_small.csv time interval mean: 0.0064822229959964756\n",
      "attack_set/HOIC_small.csv time interval std: 0.008688119431468546\n",
      "attack_set/HOIC_small.csv time interval max: 0.051918983459472656\n",
      "attack_set/HOIC_small.csv time interval min: 0.0\n",
      "attack_set/BruteForce-Web.csv time interval mean: 0.4611680051644539\n",
      "attack_set/BruteForce-Web.csv time interval std: 0.6562899844458695\n",
      "attack_set/BruteForce-Web.csv time interval max: 5.889467000961304\n",
      "attack_set/BruteForce-Web.csv time interval min: 0.0\n",
      "attack_set/LOIC_UDP_small.csv time interval mean: 0.0001158337263284843\n",
      "attack_set/LOIC_UDP_small.csv time interval std: 0.004895723431399497\n",
      "attack_set/LOIC_UDP_small.csv time interval max: 0.44814610481262207\n",
      "attack_set/LOIC_UDP_small.csv time interval min: 0.0\n",
      "attack_set/SQL_Injection.csv time interval mean: 1.010356331139468\n",
      "attack_set/SQL_Injection.csv time interval std: 1.9985051081213048\n",
      "attack_set/SQL_Injection.csv time interval max: 5.0104148387908936\n",
      "attack_set/SQL_Injection.csv time interval min: 0.0\n",
      "attack_set/ssldosA.csv time interval mean: 0.025138188380187065\n",
      "attack_set/ssldosA.csv time interval std: 1.8880601184964565\n",
      "attack_set/ssldosA.csv time interval max: 173.135183095932\n",
      "attack_set/ssldosA.csv time interval min: 0.0\n",
      "attack_set/fuzzscan.csv time interval mean: 0.2219464788733033\n",
      "attack_set/fuzzscan.csv time interval std: 0.8464270708858663\n",
      "attack_set/fuzzscan.csv time interval max: 10.000676155090332\n",
      "attack_set/fuzzscan.csv time interval min: 0.0\n",
      "attack_set/BruteForce-XSS.csv time interval mean: 0.3745094517049896\n",
      "attack_set/BruteForce-XSS.csv time interval std: 0.4525943918523675\n",
      "attack_set/BruteForce-XSS.csv time interval max: 5.015658140182495\n",
      "attack_set/BruteForce-XSS.csv time interval min: 0.0\n",
      "train_set/benign1.csv time interval mean: 0.0013886425206883909\n",
      "train_set/benign1.csv time interval std: 0.009868342330922302\n",
      "train_set/benign1.csv time interval max: 0.3240790367126465\n",
      "train_set/benign1.csv time interval min: 0.0\n",
      "train_set/benign2.csv time interval mean: 0.0013806035162350586\n",
      "train_set/benign2.csv time interval std: 0.009658550591825571\n",
      "train_set/benign2.csv time interval max: 0.3665339946746826\n",
      "train_set/benign2.csv time interval min: 0.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "benign_filenames = [os.path.join(\"train_set\", \"benign\" + str(i) + \".csv\") \n",
    "                    for i in range(1, 3)]\n",
    "attack_filenames = [os.path.join(\"attack_set\", x) for x in \n",
    "                    os.listdir(\"attack_set\") if x.endswith(\".csv\")]\n",
    "for filename in attack_filenames + benign_filenames:\n",
    "    df = pd.read_csv(filename)\n",
    "    df_group = df.groupby([\"src_ip\", \"dst_ip\", \"src_port\", \"dst_port\", \"protocol\"])\n",
    "    total_time_interval = []\n",
    "    for name, group in df_group:\n",
    "        time_interval = [0] + list(np.diff(group[\"timestamp\"].values))\n",
    "        total_time_interval += time_interval\n",
    "    print(f\"{filename} time interval mean: {np.mean(total_time_interval)}\")\n",
    "    print(f\"{filename} time interval std: {np.std(total_time_interval)}\")\n",
    "    print(f\"{filename} time interval max: {np.max(total_time_interval)}\")\n",
    "    print(f\"{filename} time interval min: {np.min(total_time_interval)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Novelty detection with One Class SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from utils import Packet, Flow\n",
    "\n",
    "def get_flows(df: pd.DataFrame, key_type: str = \"default\") -> dict:\n",
    "    mp = dict()\n",
    "    for idx in range(len(df)): # simulate the process of packet processing\n",
    "        row = df.iloc[idx]\n",
    "        pkt = Packet(\n",
    "            src_ip=row[\"src_ip\"],\n",
    "            dst_ip=row[\"dst_ip\"],\n",
    "            src_port=row[\"src_port\"],\n",
    "            dst_port=row[\"dst_port\"],\n",
    "            protocol=row[\"protocol\"],\n",
    "            proto_code=row[\"proto_code\"],\n",
    "            pkt_length=row[\"pkt_length\"],\n",
    "            timestamp=row[\"timestamp\"],\n",
    "            ttl=row[\"ttl\"],\n",
    "            tcp_window=row[\"tcp_window\"],\n",
    "            tcp_dataoffset=row[\"tcp_dataoffset\"],\n",
    "            udp_length=row[\"udp_length\"],\n",
    "        )\n",
    "        key = pkt.key(type=key_type)\n",
    "        if key not in mp:\n",
    "            mp[key] = Flow()\n",
    "        mp[key].add_packet(pkt)\n",
    "    return mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import whisper_config\n",
    "\n",
    "def transform(mp: dict, all_flows: bool = False):\n",
    "    packet_data = []\n",
    "    for key, flow in mp.items():\n",
    "        data = flow.packet_vector()\n",
    "        if all_flows: # short & long flow features\n",
    "            packet_data.append(data)\n",
    "        elif len(data) <= (whisper_config[\"n_fft\"] // 2): # short flows\n",
    "            packet_data.append(data)\n",
    "    return packet_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "all_flows = False\n",
    "train_benign_filename = os.path.join(\"dataset\", \"benign_small.csv\")\n",
    "# train_benign_filename = os.path.join(\"train_set\", \"benign1.csv\")\n",
    "\n",
    "# df_benign = pd.read_csv(os.path.join(\"train_set\", \"benign1.csv\"))\n",
    "df_benign = pd.read_csv(train_benign_filename)\n",
    "train_flow_dict = get_flows(df_benign)\n",
    "train_packet_data = transform(train_flow_dict, all_flows=all_flows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LocalOutlierFactor(novelty=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LocalOutlierFactor</label><div class=\"sk-toggleable__content\"><pre>LocalOutlierFactor(novelty=True)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LocalOutlierFactor(novelty=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "# clf = OneClassSVM(kernel=\"rbf\", nu=0.1)\n",
    "clf = LocalOutlierFactor(novelty=True)\n",
    "clf.fit(train_packet_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import json\n",
    "import os\n",
    "import torch\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of train_set/benign1.csv: 36.16%\n",
      "Accuracy of train_set/benign2.csv: 35.93%\n",
      "Accuracy of attack_set/LDoS_small.csv: 100.00%\n",
      "Accuracy of attack_set/osscan.csv: 99.22%\n",
      "Accuracy of attack_set/infiltration.csv: 100.00%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mfor\u001b[39;00m filename \u001b[39min\u001b[39;00m attack_filenames:\n\u001b[1;32m     14\u001b[0m     df_attack \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(filename)\n\u001b[0;32m---> 15\u001b[0m     attack_flow_dict \u001b[39m=\u001b[39m get_flows(df_attack)\n\u001b[1;32m     16\u001b[0m     attack_packet_data \u001b[39m=\u001b[39m transform(attack_flow_dict, all_flows\u001b[39m=\u001b[39mall_flows)\n\u001b[1;32m     17\u001b[0m     y_pred \u001b[39m=\u001b[39m clf\u001b[39m.\u001b[39mpredict(attack_packet_data)\n",
      "Cell \u001b[0;32mIn[2], line 20\u001b[0m, in \u001b[0;36mget_flows\u001b[0;34m(df, key_type)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(df)): \u001b[39m# simulate the process of packet processing\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     row \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39miloc[idx]\n\u001b[1;32m      8\u001b[0m     pkt \u001b[39m=\u001b[39m Packet(\n\u001b[1;32m      9\u001b[0m         src_ip\u001b[39m=\u001b[39mrow[\u001b[39m\"\u001b[39m\u001b[39msrc_ip\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m     10\u001b[0m         dst_ip\u001b[39m=\u001b[39mrow[\u001b[39m\"\u001b[39m\u001b[39mdst_ip\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m     11\u001b[0m         src_port\u001b[39m=\u001b[39mrow[\u001b[39m\"\u001b[39m\u001b[39msrc_port\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m     12\u001b[0m         dst_port\u001b[39m=\u001b[39mrow[\u001b[39m\"\u001b[39m\u001b[39mdst_port\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m     13\u001b[0m         protocol\u001b[39m=\u001b[39mrow[\u001b[39m\"\u001b[39m\u001b[39mprotocol\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m     14\u001b[0m         proto_code\u001b[39m=\u001b[39mrow[\u001b[39m\"\u001b[39m\u001b[39mproto_code\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m     15\u001b[0m         pkt_length\u001b[39m=\u001b[39mrow[\u001b[39m\"\u001b[39m\u001b[39mpkt_length\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m     16\u001b[0m         timestamp\u001b[39m=\u001b[39mrow[\u001b[39m\"\u001b[39m\u001b[39mtimestamp\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m     17\u001b[0m         ttl\u001b[39m=\u001b[39mrow[\u001b[39m\"\u001b[39m\u001b[39mttl\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m     18\u001b[0m         tcp_window\u001b[39m=\u001b[39mrow[\u001b[39m\"\u001b[39m\u001b[39mtcp_window\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m     19\u001b[0m         tcp_dataoffset\u001b[39m=\u001b[39mrow[\u001b[39m\"\u001b[39m\u001b[39mtcp_dataoffset\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m---> 20\u001b[0m         udp_length\u001b[39m=\u001b[39mrow[\u001b[39m\"\u001b[39;49m\u001b[39mudp_length\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m     21\u001b[0m     )\n\u001b[1;32m     22\u001b[0m     key \u001b[39m=\u001b[39m pkt\u001b[39m.\u001b[39mkey(\u001b[39mtype\u001b[39m\u001b[39m=\u001b[39mkey_type)\n\u001b[1;32m     23\u001b[0m     \u001b[39mif\u001b[39;00m key \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mp:\n",
      "File \u001b[0;32m~/anaconda3/envs/PRO/lib/python3.10/site-packages/pandas/core/series.py:981\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    978\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[key]\n\u001b[1;32m    980\u001b[0m \u001b[39melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m--> 981\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_value(key)\n\u001b[1;32m    983\u001b[0m \u001b[39mif\u001b[39;00m is_hashable(key):\n\u001b[1;32m    984\u001b[0m     \u001b[39m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[1;32m    985\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    986\u001b[0m         \u001b[39m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/PRO/lib/python3.10/site-packages/pandas/core/series.py:1090\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1088\u001b[0m \u001b[39m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[1;32m   1089\u001b[0m loc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39mget_loc(label)\n\u001b[0;32m-> 1090\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex\u001b[39m.\u001b[39;49m_get_values_for_loc(\u001b[39mself\u001b[39;49m, loc, label)\n",
      "File \u001b[0;32m~/anaconda3/envs/PRO/lib/python3.10/site-packages/pandas/core/indexes/base.py:5934\u001b[0m, in \u001b[0;36mIndex._get_values_for_loc\u001b[0;34m(self, series, loc, key)\u001b[0m\n\u001b[1;32m   5929\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   5930\u001b[0m \u001b[39m    Should an integer key be treated as positional?\u001b[39;00m\n\u001b[1;32m   5931\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m   5932\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mholds_integer()\n\u001b[0;32m-> 5934\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_values_for_loc\u001b[39m(\u001b[39mself\u001b[39m, series: Series, loc, key):\n\u001b[1;32m   5935\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   5936\u001b[0m \u001b[39m    Do a positional lookup on the given Series, returning either a scalar\u001b[39;00m\n\u001b[1;32m   5937\u001b[0m \u001b[39m    or a Series.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5941\u001b[0m \u001b[39m    key is included for MultiIndex compat.\u001b[39;00m\n\u001b[1;32m   5942\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m   5943\u001b[0m     \u001b[39mif\u001b[39;00m is_integer(loc):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "accuracy_dict = {}\n",
    "\n",
    "for filename in benign_filenames:\n",
    "    df_benign = pd.read_csv(filename)\n",
    "    train_flow_dict = get_flows(df_benign)\n",
    "    train_packet_data = transform(train_flow_dict, all_flows=all_flows)\n",
    "    y_pred = clf.predict(train_packet_data)\n",
    "    y_true = [1] * len(train_packet_data)\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    print(\"Accuracy of {}: {:.2f}%\".format(filename, acc * 100))\n",
    "    accuracy_dict[filename] = acc\n",
    "\n",
    "for filename in attack_filenames:\n",
    "    df_attack = pd.read_csv(filename)\n",
    "    attack_flow_dict = get_flows(df_attack)\n",
    "    attack_packet_data = transform(attack_flow_dict, all_flows=all_flows)\n",
    "    y_pred = clf.predict(attack_packet_data)\n",
    "    y_true = [-1] * len(attack_packet_data)\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    print(\"Accuracy of {}: {:.2f}%\".format(filename, acc * 100))\n",
    "    accuracy_dict[filename] = acc\n",
    "\n",
    "accuracy_base_name = \"short-accuracy.json\" if not all_flows else \"all-accuracy.json\"\n",
    "accuracy_save_path = os.path.join(\"result\", \"packet\", \"lof\", os.path.basename(train_benign_filename), accuracy_base_name)\n",
    "os.makedirs(os.path.dirname(accuracy_save_path), exist_ok=True)\n",
    "with open(accuracy_save_path, \"w\") as f:\n",
    "    json.dump(accuracy_dict, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detect with kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_kmeans(train_data, save_path, n_clusters):\n",
    "    train_data = torch.tensor(train_data)\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=0)\n",
    "    kmeans.fit(train_data.cpu().numpy())\n",
    "\n",
    "    centroids = torch.tensor(kmeans.cluster_centers_)\n",
    "    train_loss = torch.cdist(train_data, centroids, p=2).min(dim=1).values.mean()\n",
    "\n",
    "    if not os.path.exists(os.path.dirname(save_path)):\n",
    "        os.makedirs(os.path.dirname(save_path))\n",
    "    with open(save_path, \"w\") as f:\n",
    "        json.dump({\n",
    "            \"centroids\": centroids.tolist(),\n",
    "            \"train_loss\": train_loss.item(),\n",
    "        }, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_kmeans(test_data, test_labels, load_path, scale=5):\n",
    "    with open(load_path, \"r\") as f:\n",
    "        model_param = json.load(f)\n",
    "    centroids = torch.tensor(model_param[\"centroids\"])\n",
    "    train_loss = model_param[\"train_loss\"]\n",
    "    \n",
    "    pred = []\n",
    "    for val in test_data:\n",
    "        val = torch.tensor(val)\n",
    "        dist = torch.norm(val - centroids, dim=1).min().item()\n",
    "        pred.append(-1 if dist > scale * train_loss else 1)\n",
    "    return accuracy_score(test_labels, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/PRO/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "kmeans_save_path = os.path.join(\"model\", \"packet\", \"kmeans\", \n",
    "                    os.path.basename(train_benign_filename), \"model.json\")\n",
    "train_kmeans(train_packet_data, kmeans_save_path, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of train_set/benign1.csv: 99.30%\n",
      "Accuracy of train_set/benign2.csv: 99.32%\n",
      "Accuracy of attack_set/LDoS_small.csv: 0.00%\n",
      "Accuracy of attack_set/osscan.csv: 0.00%\n",
      "Accuracy of attack_set/infiltration.csv: 33.33%\n",
      "Accuracy of attack_set/HOIC_small.csv: 0.00%\n",
      "Accuracy of attack_set/BruteForce-Web.csv: 25.18%\n",
      "Accuracy of attack_set/LOIC_UDP_small.csv: 0.00%\n",
      "Accuracy of attack_set/SQL_Injection.csv: 2.94%\n",
      "Accuracy of attack_set/ssldosA.csv: 3.33%\n",
      "Accuracy of attack_set/fuzzscan.csv: 0.00%\n",
      "Accuracy of attack_set/BruteForce-XSS.csv: 46.51%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "accuracy_dict = {}\n",
    "\n",
    "for filename in benign_filenames:\n",
    "    df_benign = pd.read_csv(filename)\n",
    "    train_flow_dict = get_flows(df_benign)\n",
    "    train_packet_data = transform(train_flow_dict, all_flows=all_flows)\n",
    "    y_true = [1] * len(train_packet_data)\n",
    "    acc = test_kmeans(train_packet_data, y_true, kmeans_save_path, 5)\n",
    "    print(\"Accuracy of {}: {:.2f}%\".format(filename, acc * 100))\n",
    "    accuracy_dict[filename] = acc\n",
    "\n",
    "for filename in attack_filenames:\n",
    "    df_attack = pd.read_csv(filename)\n",
    "    attack_flow_dict = get_flows(df_attack)\n",
    "    attack_packet_data = transform(attack_flow_dict, all_flows=all_flows)\n",
    "    y_true = [-1] * len(attack_packet_data)\n",
    "    acc = test_kmeans(attack_packet_data, y_true, kmeans_save_path, 5)\n",
    "    print(\"Accuracy of {}: {:.2f}%\".format(filename, acc * 100))\n",
    "    accuracy_dict[filename] = acc\n",
    "\n",
    "accuracy_base_name = \"short-accuracy.json\" if not all_flows else \"all-accuracy.json\"\n",
    "accuracy_save_path = os.path.join(\"result\", \"packet\", \"kmeans\", \n",
    "                    os.path.basename(train_benign_filename), accuracy_base_name)\n",
    "os.makedirs(os.path.dirname(accuracy_save_path), exist_ok=True)\n",
    "with open(accuracy_save_path, \"w\") as f:\n",
    "    json.dump(accuracy_dict, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PRO",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
